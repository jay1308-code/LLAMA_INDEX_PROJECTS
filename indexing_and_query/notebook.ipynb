{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']= os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorStoreIndex : it will convert the text into vector and also assigns the index to it\n",
    "# SimpleDirectoryReader : it will read the data from the directory\n",
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
    "documents=SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='70045b78-78ee-473b-a9f6-653fcca6ac1b', embedding=None, metadata={'page_label': '1', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b8f0a87f-b166-472f-be6f-e55337476994', embedding=None, metadata={'page_label': '2', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 Introduction\\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [ 21] and conditional\\ncomputation [ 32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence\\nof continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output\\nsequence (y1, ..., y m)of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1408962b-77b1-431f-bc5f-460912ab7046', embedding=None, metadata={'page_label': '3', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [ 11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm( x+ Sublayer( x)), where Sublayer( x)is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512 .\\nDecoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position ican depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='05bbc716-fca6-42b8-812b-fa9e37e077b8', embedding=None, metadata={'page_label': '4', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by√dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices KandV. We compute\\nthe matrix of outputs as:\\nAttention( Q, K, V ) = softmax(QKT\\n√dk)V (1)\\nThe two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof1√dk. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dkthe two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk[3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients4. To counteract this effect, we scale the dot products by1√dk.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk,dkanddvdimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of qandkare independent random\\nvariables with mean 0and variance 1. Then their dot product, q·k=Pdk\\ni=1qiki, has mean 0and variance dk.\\n4', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c12a15f9-023d-4661-8bfc-02937e5bcdde', embedding=None, metadata={'page_label': '5', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead( Q, K, V ) = Concat(head 1, ...,head h)WO\\nwhere head i= Attention( QWQ\\ni, KWK\\ni, V WV\\ni)\\nWhere the projections are parameter matrices WQ\\ni∈Rdmodel×dk,WK\\ni∈Rdmodel×dk,WV\\ni∈Rdmodel×dv\\nandWO∈Rhdv×dmodel.\\nIn this work we employ h= 8 parallel attention layers, or heads. For each of these we use\\ndk=dv=dmodel/h= 64 . Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n•In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n•The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n•Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN( x) = max(0 , xW 1+b1)W2+b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512 , and the inner-layer has dimensionality\\ndff= 2048 .\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [ 30]. In the embedding layers, we multiply those weights by√dmodel.\\n5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='938b045d-11b7-47a4-b254-fed587eefdc2', embedding=None, metadata={'page_label': '6', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. nis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i)=sin(pos/100002i/d model)\\nPE(pos,2i+1)=cos(pos/100002i/d model)\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2πto10000 ·2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k,PEpos+kcan be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [ 9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., x n)to another sequence of equal length (z1, ..., z n), with xi, zi∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [ 12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n)sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2afb5b44-0e3c-4f9c-94a9-a7d6fa441102', embedding=None, metadata={'page_label': '7', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='length nis smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [ 31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k)convolutional layers in the case of contiguous kernels,\\norO(logk(n))in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k·n·d+n·d2). Even with k=n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [ 38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [ 20] with β1= 0.9,β2= 0.98andϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate =d−0.5\\nmodel·min(step_num−0.5, step _num·warmup _steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup _steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup _steps = 4000 .\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6a641e74-de5c-4ef6-a52f-d7596476c93d', embedding=None, metadata={'page_label': '8', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModelBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0·1020\\nGNMT + RL [38] 24.6 39.92 2.3·10191.4·1020\\nConvS2S [9] 25.16 40.46 9.6·10181.5·1020\\nMoE [32] 26.03 40.56 2.0·10191.2·1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0·1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8·10201.1·1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7·10191.2·1021\\nTransformer (base model) 27.3 38.1 3.3·1018\\nTransformer (big) 28.4 41.8 2.3·1019\\nResidual Dropout We apply dropout [ 33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop= 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls= 0.1[36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5days on 8P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop= 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4and length penalty α= 0.6[38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9924425c-6b35-471d-959f-81b5187763d3', embedding=None, metadata={'page_label': '9', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dvPdrop ϵlstrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B)16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dkhurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [ 9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [ 25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='73b2e397-1140-436c-8121-5d5938c032a4', embedding=None, metadata={'page_label': '10', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21andα= 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [ 37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor .\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1]Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450 , 2016.\\n[2]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR , abs/1409.0473, 2014.\\n[3]Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR , abs/1703.03906, 2017.\\n[4]Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733 , 2016.\\n10', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9fa57af-f49c-49b6-9322-f632a3c3055c', embedding=None, metadata={'page_label': '11', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[5]Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR , abs/1406.1078, 2014.\\n[6]Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357 , 2016.\\n[7]Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR , abs/1412.3555, 2014.\\n[8]Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL , 2016.\\n[9]Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2 , 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850 , 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition , pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation ,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410 , 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS) , 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR) , 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2 ,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nInInternational Conference on Learning Representations , 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722 , 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130 , 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114 , 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025 , 2015.\\n11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='55f69141-84b1-48c2-9906-41f3ed23a162', embedding=None, metadata={'page_label': '12', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics , 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference ,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing , 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304 , 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL , pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859 , 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909 , 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538 , 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research , 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28 , pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems , pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR , abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems , 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144 , 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR , abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers) , pages 434–443. ACL, August 2013.\\n12', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2467f002-3ca5-4ef1-a5bf-f85b85200d1c', embedding=None, metadata={'page_label': '13', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='db49845c-d580-4070-a97c-97c82a2ebee7', embedding=None, metadata={'page_label': '14', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b1ce58d7-e11d-4eea-884f-8b75726a4766', embedding=None, metadata={'page_label': '15', 'file_name': '1706.03762v7.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\1706.03762v7.pdf', 'file_type': 'application/pdf', 'file_size': 2215244, 'creation_date': '2024-04-09', 'last_modified_date': '2024-04-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='74699f44-eb3a-4ed5-a5c2-eda62afc3315', embedding=None, metadata={'page_label': '1', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Cue-CoT: Chain-of-thought Prompting for Responding\\nto In-depth Dialogue Questions with LLMs\\nHongru Wang1∗, Rui Wang2,6∗, Fei Mi3, Yang Deng4, Zezhong Wang1\\nBin Liang1, Ruifeng Xu2,5,6, Kam-Fai Wong1†\\n1MoE Key Laboratory of High Confidence Software Technologies\\nThe Chinese University of Hong Kong\\n2Harbin Institute of Technology, Shenzhen, China3Huawei Noah’s Ark Lab\\n4National University of Singapore5Peng Cheng Laboratory, Shenzhen, China\\n6Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies\\n{hrwang, kfwong}@se.cuhk.edu.hk ruiwangnlp@outlook.com\\nAbstract\\nLarge Language Models (LLMs), such as\\nChatGPT , greatly empower dialogue systems\\nwith strong language understanding and gener-\\nation capabilities. However, most of the pre-\\nvious works prompt the LLMs to directly gen-\\nerate a response based on the dialogue con-\\ntext, overlooking the underlying linguistic cues\\nabout the user status exhibited in the context.\\nSuch in-depth dialogue scenarios are challeng-\\ning for existing LLMs to figure out the user’s\\nhidden needs and respond satisfactorily through\\na single-step inference. To this end, we propose\\na novel linguistic cue-based chain-of-thoughts\\n(Cue-CoT), which enhances the LLMs infer-\\nence with an intermediate reasoning step to\\nfind cues exhibited in the dialogue, aiming to\\nprovide a more personalized and engaging re-\\nsponse. To evaluate the approach, we build a\\nbenchmark with in-depth dialogue questions,\\nconsisting of 6 datasets in both Chinese and\\nEnglish, targeting 3 major linguistic cues dur-\\ning the conversation: personality ,emotion , and\\npsychology . We conduct extensive experiments\\non the proposed benchmark with 5 LLMs under\\nboth zero-shot and one-shot settings. Empiri-\\ncal results demonstrate our proposed Cue-CoT\\nmethod outperforms standard prompting meth-\\nods in terms of both helpfulness andacceptabil-\\nityon all datasets.\\n1 Introduction\\nLarge Language Models (LLMs), or foundation\\nmodels (Zhou et al., 2023), especially after the ap-\\npearance of ChatGPT1, recently revolutionize the\\nparadigm of various natural language processing\\n(NLP) tasks, including dialogue response gener-\\nation tasks (Bang et al., 2023). However, most\\nexisting LLM-based studies directly feed the user\\n∗Equal Contribution.\\n†Corresponding Author.\\n1https://openai.com/blog/chatgptquery or dialogue content to the LLM for gener-\\nating a response with a preceding prompt, mak-\\ning the responses stereotypical and tedious, espe-\\ncially for in-depth dialogue questions (Zhao et al.,\\n2023). On the contrary, it is widely acknowledged\\nthat dialogue contexts generally convey a lot of\\ninformation about the user status in addition to\\nthe pure semantic information from a linguistic\\nperspective (Mairesse et al., 2007; Tausczik and\\nPennebaker, 2010; Schwartz et al., 2013). Specifi-\\ncally, the linguistic cues underlying dialogue con-\\ntext have been shown to be an effective means of\\nrevealing the emotions (Ekman, 1971), personality\\ntraits (Mairesse et al., 2007), psychological char-\\nacteristics (Tausczik and Pennebaker, 2010), and\\nother relevant information of users (Turney, 2002;\\nNewman et al., 2003). Consequently, recognizing\\nand understanding these cues exhibited in the con-\\ntext of dialogues becomes crucial to comprehend\\nuser intentions and status (Rashkin et al., 2019). By\\ndoing so, a dialogue system can generate responses\\nthat align with the user’s expectations, meet their\\nunique needs and preferences, and ultimately strive\\ntowards constructing a human-like conversational\\nexperience (Salemi et al., 2023).\\nInspired by the emergent capabilities of LLMs\\non reasoning over texts (Wei et al., 2022), while pre-\\nvious efforts mostly investigate in-context learning\\n(Huang et al., 2022) or chain-of-thought prompt-\\ning schemes (Wei et al., 2023) on text classifica-\\ntion (Zhang et al., 2022) and question answering\\n(Press et al., 2022; Shum et al., 2023; Margatina\\net al., 2023), we take advantage of LLMs to reason\\nfor dialogue (Lee et al., 2023), which, to our best\\nknowledge, has not been thoroughly investigated\\nyet. Specifically, we design a linguistic cue-based\\nchain-of-thoughts ( Cue-CoT), consisting of two\\nvariants: O-Cue CoT and M-Cue CoT in which\\nthe former one outputs intermediate reasoning re-arXiv:2305.11792v2  [cs.CL]  15 Oct 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2ad67dec-b47c-48fc-8f12-29ec896d4593', embedding=None, metadata={'page_label': '2', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"User:If we only rely on free online teaching, can welearn the violin? What about the piano?System:Yes, but with a conscious learning spirit and patient practice…..User:Can welearn violin and piano fromscratch?ModelInput\\nSystem:Yes, as long as you are willing to spend time and energy on learning and practicing, and constantly improve your skills, you can learn violin and piano from scratch. At the same time, it is recommended that you consider finding a professional teacher for guidance, which will improve the learning effect more effectively. Have you considered looking for a professional teacher?ModelOutputHereistheconversationbetweenuserandsystem.{DIALOGUE_CONTEXT}Pleaseinfertheuserstatusexhibitedintheconversationsuchas….StandardPromptingM-CueCoTPromptinginDialogue\\nSCORES8/10ModelInputHereistheconversationbetweenuserandsystem.{DIALOGUE_CONTEXT}Pleasefirstoutputasinglelinecontaininguserstatussuchastheuser‘spersonalitytraits,psychologicalandemotionalstatesexhibitedintheconversation.Inthesubsequentline,pleaseplayaroleassystemandgeneratearesponsebasedontheuserstatusandthedialoguecontext.System:Sure! For learning the violin and piano from scratch, the most important thing is your learning attitude and patience in practice. Violin skills are relatively high, and it may be difficult to master them from scratch, but as long as you maintain a conscious learning spirit and continuous practice, you can gradually master violin skills. For piano, it is relatively easier to learn. As long as you have a certain sense of rhythm and music foundation, it is feasible to learn piano from scratch.O-CueCoTPromptinginDialogueModelInput\\nModelOutput\\nSCORES8.5/10UserStatus:The user has some interest in music and a willingness to learn,(Personaliaty)but may lack confidence and patience(Psychology)......as well as some anxiety and worry.(Emotions)ModelOutputUserStatus:The status shown by the user is curiosity, a mindset of curiosity and eagerness to learn.Intermediatereasoning Hereistheconversationbetweenuserandsystem.{DIALOGUE_CONTEXT}Hereistheuserstatus.{USER_STATUS}Please playaroleassystem……ModelInput\\nSystem:Sure! As long asyou have enough enthusiasm and patience for learning, as well as the determination to learn music, learning violin and piano is completely achievable. (Answer the questions) When you get stuck, don't lose heart because learning any skill takes time and effort. (Encouragement) At the same time, you can also find some professional teachers or other learning resources to help you better master skills and basic skills. Believe in yourself, you can become an excellent violinist or pianist! (Giveconfidence)SCORES9/10ModelOutputStep1Step2Figure 1: An example of different prompting for responding to in-depth dialog questions with LLMs, including\\nstandard prompting, O-Cue CoT, and M-Cue CoT. We shadow the intermediate reasoning results, i.e.,the personality,\\nempathy, and psychological status of the user, and highlight the instructions at the input and indicate the roles of\\ndifferent parts of the response (in green) in M-Cue CoT.\\nsults with a final response in one-step but the latter\\nreasons step by step, as shown in Figure 1. In\\ndetail, with standard prompting, LLM-based sys-\\ntems directly generate the response given the dia-\\nlogue context. Regarding the user status implied\\nby the context as intermediate reasoning results\\n(CueCoT), we prompt the system to infer the user\\nstatus first and then generate a response based on\\ndialogue context and user status.\\nTo evaluate our approach, we build a bench-\\nmark, consisting of 6in-depth dialogue datasets\\nin both Chinese and English, considering three ma-\\njor aspects of user statuses: personality ,emotions ,\\nandpsychology , exhibited during the conversation,\\nforming a comprehensive evaluation benchmark\\nincorporating various user statuses in the context\\nof dialogue response generation. We conduct ex-\\ntensive experiments with 5LLM-based dialogue\\nsystems based on the benchmark using the afore-\\nmentioned three types of prompting schemes. To\\nsum up, our contributions can be summarized be-\\nlow:\\n• We construct an in-depth dialogue evaluation\\nbenchmark considering the personality, emo-\\ntion, and psychology of users exhibited in the\\nconversation, with the goal of aligning with\\nunique user needs and status, which consists\\nof 6 datasets, and 7.3k dialogues2.\\n•We propose two effective dialogue cots: O-\\nCue CoT and M-Cue CoT, that enable ad-\\n2Our dataset and demo are released here: https://\\ngithub.com/ruleGreen/Cue-CoT .vanced reasoning and planning based on user\\nstatuses. Additionally, we suggest utilizing\\nintermediate reasoning results as a criterion\\nfor selecting demonstrations in limited train-\\ning data scenarios, specifically in one-shot\\nsettings.\\n•Our findings demonstrate that both the O-\\nCue CoT and M-Cue CoT approaches out-\\nperform standard prompting in generating\\nmore helpful and acceptable responses for the\\nusers. Specifically, the M-Cue CoT shows su-\\nperior robustness and reasoning performance\\nin all datasets and all LLMs. Furthermore,\\nour novel demonstration selection strategy ex-\\nhibits superior performance under both ran-\\ndom selection andtop-1 selection .\\n2 Related Work\\nChain-of-thought Prompt. Following the initial\\nchain-of-thought prompting (Wei et al., 2023), lots\\nof works spring up aim to improve different parts of\\noriginal reasoning processing, including auto-cot\\n(Zhang et al., 2022), self-consistency(Wang et al.,\\n2023e), active prompt (Diao et al., 2023), automate-\\ncot (Shum et al., 2023). Besides that, a further line\\nof work studies in-context learning (Brown et al.,\\n2020) as its efficiency and effectiveness with LLMs\\nas backbones in which the key of it is to select in-\\nformative demonstrations to prepend the input as\\nadditional information to get better results (Liu\\net al., 2022). To find the best demonstrations and\\nunleash LLMs’ power, Liu et al. (2022) propose\\nto retrieve examples that are semantically similar\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0d104883-780f-4995-a43a-6c7fe815bb9e', embedding=None, metadata={'page_label': '3', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='to a test query sample while some works utilize\\nuncertainty (Diao et al., 2023) or diversity (Li and\\nQiu, 2023) to refine and evaluate the selected exam-\\nples. Also, few works (Deng et al., 2023a) focus on\\nthe intermediate reasoning steps, and they use the\\nreasoning complexity (Fu et al., 2023), i.e., chains\\nwith more reasoning steps, making the effective\\ndemonstration.\\nDialogue System. Most of the previous work\\ndevelops personalized (Zhang et al., 2018; Zheng\\net al., 2020; Song et al., 2021; Chen et al., 2023a),\\nemotional (Ghosal et al., 2020; Liu et al., 2021;\\nZheng et al., 2023a; Deng et al., 2023c; Zheng\\net al., 2023b), empathetic (Rashkin et al., 2019;\\nZheng et al., 2021; Sabour et al., 2022) dialogue\\nsystem in isolation, rather than seamlessly blend-\\ning them all into one cohesive conversational flow\\n(Smith et al., 2020; Wang et al., 2023a). A com-\\nmon approach is to predict the emotion or persona\\nfrom a pre-defined set and generate the response in\\na multi-task manner (Ma et al., 2021; Zheng et al.,\\n2021; Sabour et al., 2022; Cheng et al., 2023; Deng\\net al., 2023b). Besides that, lots of work notices\\nthese linguistic cues underneath text by directly\\npredicting them independently as a classification\\ntask (Wang et al., 2022; Barriere et al., 2022; Ghosh\\net al., 2022). Distinguishing from these previous\\nworks, we regard different aspects of cues as part\\nof user status and prompt the LLMs to reason user\\nstatus exhibited in the dialogue context, aiming to\\ngenerate more helpful and acceptable responses for\\nusers.\\n3 Method\\nIn this section, we introduce more details about our\\nmethod and how we select demonstrations under\\nthe few-shot setting.\\n3.1 Chain-of-thought in Dialogue\\nWe describe the prompting schemes in a general\\nform, including standard prompting, O-Cue CoT,\\nandM-Cue CoT as presented in Figure 1.\\nStandard Prompting. Most of the previous works\\ndirectly prompt LLMs to generate responses solely\\nbased on dialogue context or user queries, which\\nlack transparency and interpretability. The objec-\\ntive is defined as:\\nM:c→r (1)where Mis parameterized by LLMs, candrde-\\nmotes dialogue context and response respectively.\\nO-Cue CoT. In line with the traditional chain-of-\\nthoughts, we prompt the models to generate the\\nmiddle reasoning processing and final results to-\\ngether, for example, we can prompt the LLMs to\\ngenerate user status and a final response simultane-\\nously giving dialogue context, enforcing the LLMs\\nto reason based on the user status. However, it is\\nimportant to note that generating intermediate rea-\\nsoning results with responses together may lead to\\na reduction in the length of the different outputs,\\nparticularly when multiple or complex reasoning\\nresults are involved, sacrificing the details and ex-\\nplanations. For example, as shown in O-Cue CoT\\nin Figure 1, the generated user status is too short\\nto provide cues for responses. Moreover, it is in-\\nfeasible to modify the intermediate results when it\\nis wrong (Wang et al., 2023c). Here, we defined\\nthe objective as follows in which sstands for user\\nstatus:\\nM:c→s,r (2)\\nM-Cue CoT. In addition to standard prompting and\\nO-Cue , we can further enhance the quality of re-\\nsponses in LLMs by decomposing reasoning into\\ndifferent consecutive steps while the final step is\\nto generate responses according to previous rea-\\nsoning outputs. On the one hand, it is convenient\\nto process these intermediate outputs, allowing for\\nactions such as incorporating user profiles for per-\\nsonalization (Salemi et al., 2023) or filtering out\\nerroneous reasoning results. These intermediate\\noutputs can also be stored for future use, enabling\\ntheir utilization for various purposes. On the other\\nhand, these intermediate results can be used as a\\ncriterion to select demonstrations under few-shot\\nsettings (See next section). Overall, this technique\\nallows for a clearer and more systematic progres-\\nsion of reasoning, resulting in better transparency\\nand interpretability. The objective can be viewed\\nas follows:\\nM:c→s→r (3)\\n3.2 Demonstration Selection\\nThe few-shot performance of LLMs depends heav-\\nily on the quality of the demonstrations, especially\\nfor complex tasks that need multiple reasoning\\nsteps (Zhang et al., 2022). Furthermore, in the con-\\ntext of dialogue systems, the process of selecting', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='505c5e81-6a5a-48f0-b8d9-e9cf33b7849e', embedding=None, metadata={'page_label': '4', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='demonstrations becomes more challenging due to\\nthe one-to-many nature of dialogue interactions. As\\na result, novel approaches are needed to tackle the\\nintricacies of dialogue response selection, taking\\ninto account the dynamic and context-dependent\\nnature of conversations. We here introduce the\\ndemonstration selection strategy of three prompt\\nschemes.\\nStandard Prompting. Following previous work\\n(Wei et al., 2023; Liu et al., 2022), we use ran-\\ndomly sampled examples ( random selection ) or\\nmost semantic similar examples ( top-1 selection )\\naccording to dialogue context c∗as our demonstra-\\ntions to form ( c,r|c∗→r∗).\\nO-Cue CoT. Figure 2 shows the demonstration se-\\nlection strategy of Cue-CoT. Although we still se-\\nlect demonstrations according to dialogue context\\ncatO-Cue CoT, the user status s1is extracted from\\nthe demonstration pool as intermediate reasoning\\nresults to enhance the reasoning ability of LLMs as\\n(c,s,r|c∗→s∗,r∗).\\nM-Cue CoT. Since there are multiple steps, we\\ndesign different selection strategies for each step.\\nSpecifically, we first select demonstrations ( c,s)\\naccording to dialogue context to infer status, and\\nthen select demonstrations ( c,s,r) according to\\nuser status. In this way, all intermediate reasoning\\nresults can be utilized as a criterion to select demon-\\nstrations, providing additional signals for the latter\\nreasoning. An assumption underneath here is that\\nusers with similar statuses tend to accept responses\\nwith a similar style. Besides that, we also apply\\nrandom selection andtop-1 selection toO-Cue CoT\\nandM-Cue CoT for detailed comparison.\\n4 Datasets Collection\\nIn order to evaluate the performance of proposed\\nCue-CoT to reason different user statuses, we col-\\nlect six datasets in terms of personality, empathy,\\nand psychology, in both Chinese and English.\\nPersonality. Previous works found that the con-\\ntent and style of a user’s inquiry can provide indi-\\nrect insights into their personality traits (Mairesse\\net al., 2007; Barriere et al., 2022). For instance, an\\nindividual with a tendency towards anxiety may\\nask for advice on how to alleviate nervousness\\nbefore an upcoming job interview, phrasing the\\nquestion as follows: \" What strategies can I em-\\nploy to reduce my anxiety and perform well in to-\\nmorrow’s interview? \". Since the public existing\\n<dialoguecontext1,userstatus1response1><dialoguecontext2,userstatus2response2><dialoguecontextn,userstatusnresponsen>…….…….SelectuserstatusContextStatusInputatStep1(𝑐,𝑠)InputatStep2ContextStatusResponse(𝑐,𝑠,𝑟)M-CueCoTO-CueCoT\\nContextStatusInput<dialoguecontext1userstatus1,response1><dialoguecontext2<dialoguecontextn…….…….userstatus2,response2>userstatusn,responsen>(𝑐,𝑠,𝑟)ResponseOutput\\nOutputFigure 2: Different demonstration selection strategies\\nofO-Cue andM-Cue CoT, while the returned results\\nsuch as (c,s,r)are prepended to original input to form\\nnew input.\\ndatasets either focus on the personae of the system\\n(Zhang et al., 2018) or target classification tasks\\nwithout providing corresponding dialogue response\\n(Barriere et al., 2022), we thus build a pipeline to\\nautomatically collect the datasets using ChatGPT\\n(gpt-3.5-turbo-0301 ). We first collect question-\\nanswer seeds from the two largest real-world online\\nQA forums: Zhihu and Quora3, and then prompt\\ntheChatGPT to infer the personality first as shown\\nin Table 9. We lastly require the ChatGPT to con-\\ntinue the dialogue given the inferred personality\\nand the question-answer seed. In order to facilitate\\nthe continuous generation of transcripts for both\\nparticipants in a dialogue, we utilize a template, as\\npresented in Appendix A.1, to establish the neces-\\nsary format and requirements. In this way, the use\\nof personality seed and question-answer seed in the\\ntemplate assures greater diversity and reliability\\nof user queries. Specifically, the personality seed\\ndetermines the style of the user query, while the\\nquestion seed determines the content. As a result,\\nthe user statuses vary across different dialogues,\\ncontributing to a richer and more varied conversa-\\ntional experience. Some examples of personality\\ncan be found in Appendix A.2.\\nEmotion. In terms of the emotional status of\\nusers, we re-organize two existing empathetic di-\\nalogue datasets: D4 (Yao et al., 2022) and Empa-\\n3https://www.zhihu.com/ andhttps://huggingface.\\nco/datasets/quora', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ecc4afc7-0c16-4866-adbd-8e861572eeee', embedding=None, metadata={'page_label': '5', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='MetricsChinese English\\nZhihu D4 PsyQA Quora ED EMH\\nAvg.C 258.4 521.0 210.9 149.6 50.2 44.2\\nAvg.R 76.9 57.9 607.5 48.3 12.9 175.8\\nSamples 1122 997 1000 1082 2091 1000\\nTable 1: Data statistics of our used datasets including\\nthree Chinese datasets and three English datasets, while\\neach of them represents different aspects of user status\\nduring the conversation. We highlight maximum Avg.C\\nand Avg.R.\\ntheticDialogues ( a.k.a, ED) (Rashkin et al., 2019).\\nFor the former one, we first identify all utterances\\nfrom the system labeled as empathic comfort for\\neach dialogue sample in the test set. From these\\ninstances, the utterance with the longest length is\\nchosen as the ground truth response, regarding pre-\\nceding utterances as corresponding dialogue con-\\ntext4. This approach ensures fairness and compa-\\nrability in evaluating the performance of LLMs,\\nparticularly because they tend to generate lengthy\\nresponses. For the ED, there are two roles in the\\ndialogue: Listener who is actively listening, and\\nSpeaker who is speaking and conveying informa-\\ntion. We follow the setting of the original paper\\n(Rashkin et al., 2019), and directly use all samples\\nin the test set. Neither the situation description writ-\\nten by the Speaker nor the emotional label is con-\\ntained (just as they were not given to the Listener\\nduring dialogue collection). Thus, the collected\\nempathetic dialogue datasets provide a standard\\nbenchmark for evaluating the LLMs’ ability to gen-\\nerate empathic responses.\\nPsychology. In order to assess the effectiveness of\\nLLMs in generating counseling responses for men-\\ntal health support, we employed two pre-existing\\ndatasets, namely PsyQA (Sun et al., 2021) and\\nEMH (Sharma et al., 2020). These datasets were\\nutilized as dialogue pools from which we selected\\nappropriate samples to serve as a benchmark for\\nevaluating the language models. In PsyQA, there\\nare 4,012 questions out of 22,341 samples that are\\nsampled to pick the highest-voted answers. We ran-\\ndomly sample 1,000 out of these 4,012 questions,\\nregarding the highest-voted answer as ground truth\\nto form a more challenging test set. We also pro-\\nvide the question description beside the question it-\\nself following the original setting (Sun et al., 2021).\\nIn EMH, there are 10k (post, response) pairs an-\\n4We also tried directly regarding the last utterance labeled\\nasempathic comfort as grounded truth response, but we found\\nmost of them are short and uninformative such as you are\\nwelcome, take care and so on.notated with three different communication mech-\\nanisms: emotional reactions ,interpretations , and\\nexplorations . We first sorted examples according\\nto the length of their answers and then uniformly\\nsampled examples with these three mechanisms,\\nforming a final test set.\\nAll. Table 1 shows the data statistics of our bench-\\nmark. The notation Avg. C signifies the mean\\ncontext length of instances, and if it exceeds a cer-\\ntain threshold, it may surpass the input context\\nlimit of LLMs5or become too lengthy for LLMs\\nto comprehend. On the other hand, Avg. R denotes\\nthe average response length. Generally, longer re-\\nsponses tend to be more comprehensive and clearer,\\npresenting a more challenging baseline for LLMs\\nto surpass. To sum up, we build a benchmark, con-\\nsisting of six datasets (three Chinese datasets and\\nthree English datasets) in terms of three aspects\\nof user status during the conversation, hoping the\\nrelease of it can facilitate the research of dialogue\\nsystems based on LLMs.\\n5 Experiment\\nIn this section, we have conducted a comprehensive\\nexperiment to compare the performance of three\\nprompting methods: standard prompting, O-Cue\\nandM-Cue CoT in the benchmark under both zero-\\nshot and one-shot settings6.\\n5.1 LLMs Family and Evaluation Details\\nLLMs Family. We compared the perfor-\\nmance of different LLMs with our bench-\\nmark, including ChatGLM-6B (Du et al., 2022),\\nBELLE-LLAMA-7B-2M (Ji et al., 2023), ChatGPT\\nfor Chinese, and Alpaca-7B (Taori et al., 2023),\\nVicuna-7B-v1.17and also ChatGPT for English.\\nWe strictly follow the commands and procedures\\nto recover the weights of these models and we\\nstrongly suggest that the reader read the original\\npaper to check more details. We set the temper-\\nature as 0.2 and top p as 0.1 for evaluation, and\\ntemperature as 0.7 and top p as 0.95 for generation\\nin all models. We use BERT (Devlin et al., 2019)\\n5For example, the input context limit of BELLE -LLAMA -\\n7B-2Mis 2048, and few of examples from D4 exceeds the limit\\nand the scenario becomes worse under the one-shot setting.\\nWe will have more detailed analysis in latter sections.\\n6Since the length of dialogue context is relatively long,\\nthe input length limit is easy to break when the number of\\nshot exceeds 1, so we choose the one-shot setting to conduct\\nin-context learning.\\n7https://github.com/lm-sys/FastChat', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84d2ae3a-3f0f-4a4b-81fa-aec6642d08fb', embedding=None, metadata={'page_label': '6', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Model PromptHelpfulness Acceptness\\nZhihu D4 PsyQA Zhihu D4 PsyQA\\nZero-shot Setting\\nBELLEO-Cue 67.40 76.34 69.31 55.82 52.50 53.43\\nM-Cue 81.54 71.60 79.25 60.23 72.41 73.65\\nCHATGLMO-Cue 48.29 56.68 33.00 32.39 39.19 31.34\\nM-Cue 85.02 72.10 83.57 66.67 51.27 55.40\\nCHATGPTO-Cue 67.91 50.40 61.90 53.14 52.38 58.15\\nM-Cue 95.57 87.88 90.34 65.22 61.08 56.12\\nOne-shot Setting\\nrandom selection\\nBELLEO-Cue 64.31 50.53 65.15 53.35 40.07 53.81\\nM-Cue 83.30 69.59 73.81 73.61 56.14 61.90\\nCHATGLMO-Cue - - - - - -\\nM-Cue 90.28 75.10 91.85 74.55 54.03 64.75\\nCHATGPTO-Cue 76.47 51.94 65.44 63.86 50.47 56.03\\nM-Cue 91.60 86.67 88.96 76.83 58.19 61.41\\ntop-1 selection\\nBELLEO-Cue 63.77 57.51 69.92 54.93 41.02 55.87\\nM-Cue 82.77 69.94 73.99 74.32 54.38 62.24\\nCHATGLMO-Cue - - - - - -\\nM-Cue 89.25 77.26 91.77 73.43 57.17 58.74\\nCHATGPTO-Cue 76.86 50.93 55.85 59.63 52.02 57.58\\nM-Cue 93.19 88.84 91.77 78.46 56.84 59.48\\nTable 2: The win rate of responses generated by our\\nmethod compared with the response with standard\\nprompting on three Chinese datasets in terms of help-\\nfulness andacceptness . The underlined numbers mean\\nthat there are about 160 to 280 valid responses out of\\n500 in this setting due to the input context limit of the\\nmodel.\\nas an encoder to select the nearest example to the\\ntest query for top-1 one-shot setting, storing the\\nmean vector of examples as sentence embedding8.\\nEvaluation. 1) Metrics: We found that most exist-\\ning automatic metrics (Rashkin et al., 2019; Sun\\net al., 2021) such as Avg.BLEU andF1can not\\nalign well with human judgments, as observed by\\nZhao et al. (2023), too. Inspired by recent auto-\\nmatic evaluation using ChatGPT as a judger which\\naligns well with the humans (Chen et al., 2023c;\\nWang et al., 2023b; Zhao et al., 2023), we mainly\\nchoose to use it to evaluate the quality of the gen-\\nerated responses in a pair-wise manner9, consider-\\ninghelpfulness andacceptability . The evaluation\\ntemplates can be found in Appendix A.3 and we\\ncalculate the win rate using #wins / ( #wins + #ties\\n+ #loses). 2) Methods: Due to the exceptional pro-\\nficiency of the LLM-based dialogue system, it is\\nrelatively easy for them to beat the ground truth re-\\nsponses in the original datasets (Appendix B.1), we\\nconsider standard prompting as a more challeng-\\n8We directly user bert-base-chinese for all Chinese\\ndatasets and bert-base-uncased for all English datasets, we\\ndo not finetune the BERT model.\\n9We noticed the very recent paper Wang et al. (2023d)\\nthat emphasizes the effects of the order of responses, and we\\nevaluate responses using suggested BPC but we found it can\\nnot lead to better alignment with humans in most cases of our\\nbenchmarks due to the complexity and diversity.ing baseline and compare the responses generated\\nusing our proposed Cue-CoT with the response\\ngenerated using standard prompting, which is more\\nfair and convincing. We also provide the human\\nevaluation result as a reference.\\n5.2 Main Experiment\\nAll. Table 2 and Table 3 present the win rate of re-\\nsponses generated by O-Cue andM-Cue CoT com-\\npared with the responses by standard prompting on\\nChinese and English datasets respectively10. De-\\nspite that there are few LLMs that perform worse\\nthan standard prompting using O-Cue due to its\\ncomplex instructions, i.e. ChatGLM in Chinese\\nandAlpaca in English, it is observed that O-Cue\\ncan achieve above 50% win rate mostly in Both\\nChinese and English. Moreover, it is exciting to\\nfind that M-Cue further boosts performance and\\nachieves higher win rates irrespective of the type of\\nlanguage model, datasets, or settings used, reveal-\\ning its robustness and effectiveness. We attribute\\nthis to the relatively easy-understanding instruc-\\ntions and clear outputs in each step of the M-Cue ,\\nsince some LLMs are incapable to follow relatively\\nlong instructions in O-Cue and output the content\\nand style as required. For example, we asked the\\nLLMs to output user status and response in two sep-\\narate lines but only a few LLMs output in the for-\\nmat, making it difficult to distinguish the response\\nfrom reasoning results. Also, the combined output\\nof the user status and response can potentially limit\\nthe length of various components, thereby account-\\ning for the disparity between O-Cue andM-Cue .\\nFurthermore, we found that the acceptability is rel-\\natively lower than helpfulness for Chinese LLMs\\nbut higher for English LLMs, especially under the\\none-shot setting, revealing the weakness of Chi-\\nnese LLMs to provide acceptable besides helpful\\nresponses.\\nChinese LLMs. Table 2 shows the performance\\nof Chinese LLMs. We surprisingly found that\\nChatGLM performs worst out of the three LLMs\\nusing O-Cue but better than BELLE (especially at\\nhelpfulness ) using M-Cue under the zero-shot set-\\nting, and then we carefully check the outputs of\\nthese LLMs and found that ChatGLM almost fully\\n10We emphasize here that the O-Cue and M-Cue in Table\\n2 and Table 3 should be regarded as O-Cue v.s. Standard\\nprompting and M-Cue v.s. Standard prompting respectively.\\nWe do not provide results of Standard prompting v.s. Standard\\nprompting since it is self-contained. It can be regarded as a\\nuniform distribution whose win rates are always 0.5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b29996c7-c7b8-4916-b99e-7c8ab37401e5', embedding=None, metadata={'page_label': '7', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Model PromptHelpfulness Acceptness\\nQuora ED EMH Quora ED EMH\\nZero-shot Setting\\nALPACAO-Cue 19.51 39.41 49.70 22.85 35.41 50.15\\nM-Cue 80.78 87.30 85.76 78.21 86.00 86.97\\nVICUNAO-Cue 56.16 71.43 59.43 55.73 65.06 63.50\\nM-Cue 81.67 91.30 80.42 77.89 90.71 82.93\\nCHATGPTO-Cue 79.47 88.31 82.83 81.47 89.92 93.71\\nM-Cue 85.83 91.98 82.93 89.09 96.79 94.93\\nOne-shot Setting\\nrandom selection\\nALPACAO-Cue - - - - - -\\nM-Cue 76.78 85.08 94.36 72.34 85.07 95.82\\nVICUNAO-Cue 60.45 70.77 63.06 60.45 68.21 67.07\\nM-Cue 79.84 91.20 79.23 83.16 92.45 87.99\\nCHATGPTO-Cue 80.33 87.32 84.94 80.33 90.80 96.06\\nM-Cue 84.31 89.78 85.71 86.64 93.94 96.70\\ntop-1 selection\\nALPACAO-Cue - - - - - -\\nM-Cue 74.54 78.70 88.69 72.27 79.55 93.43\\nVICUNAO-Cue 63.10 71.75 62.31 62.04 67.21 67.76\\nM-Cue 78.70 90.12 79.10 82.08 92.96 88.96\\nCHATGPTO-Cue 81.15 87.42 81.40 80.24 89.92 91.84\\nM-Cue 88.08 91.37 86.87 91.21 95.95 96.12\\nTable 3: The win rate of responses generated by our\\nmethod compared with the response with standard\\nprompting on three English datasets in terms of help-\\nfulness andacceptness . The underlined dataset mean\\nthat there are about 330 valid responses out of 500 in\\nthis dataset for all experiments due to the input context\\nlimit of the model.\\nignore the instructions in O-Cue and simply con-\\ntinue the dialogue. However, we found it can fol-\\nlow instructions well in M-Cue , resulting in higher\\nwin rates. We attribute this to the relatively more\\ncomplex and longer instructions in O-Cue and poor\\ncomplex-instructions understanding of ChatGLM11.\\nIn addition, with the M-Cue method, we found that\\nthe performance of all models on D4 is relatively\\nworse than the other two datasets. We suspect the\\nreason is the longest length of context in D4. More-\\nover, we observe that the responses generated by\\nChatGLM andBELLE under the one-shot setting are\\nmuch better under the zero-shot setting using the\\nstandard prompting method, i.e.,less general re-\\nsponses and more responses in line with the role,\\nbenefiting from the informative demonstrations.\\nEnglish LLMs. Table 3 shows the performance of\\nEnglish LLMs. Similarly, for the zero-shot setting\\nusing O-Cue , we found that Alpaca hardly follows\\nthe instructions, which often produces ambiguous\\noutputs, mostly presenting user status and other\\ntimes providing the response without any indica-\\ntion12. Besides that, with the M-Cue method, due\\nto the innate limitations of Alpaca , the win rate\\n11Thus, we do not report the one-shot results using O-Cue\\nforChatGLM .\\n12We do not report one-shot for Alpaca , too.Method Order Quora ED EMH\\nhelpfulness\\nO-CueS – O 34 (0.08) 44(0.15) 42(0.05)\\nO – S 68 (0.09) 80(0.19) 78(0.22)\\nM-CueS – O 51 (0.18) 53(0.17) 60(0.30)\\nO – S 82 (0.23) 79(0.31) 81(0.35)\\nacceptability\\nO-CueS – O 28 (0.05) 34(0.09) 34(0.08)\\nO – S 66 (0.12) 76(0.15) 88(0.57)\\nM-CueS – O 49 (0.13) 51(0.15) 50(0.21)\\nO – S 84 (0.25) 82(0.32) 75(0.14)\\nTable 4: The alignment results (Acc (Kap.C)) of dif-\\nferent automatic evaluation methods with the human\\nevaluation under the zero-shot setting by comparing\\nresponses using our CoTs with one using standard\\nprompting in terms of helpfulness andacceptability\\n(with ChatGPT as base model) on English datasets.\\nMethod Order Zhihu D4 PsyQA\\nhelpfulness\\nO-CueS – O 64 (0.23) 42(0.13) 44(0.06)\\nO – S 66 (0.37) 76(0.36) 72(0.17)\\nM-CueS – O 45 (0.14) 67(0.08) 37(0.09)\\nO – S 80 (0.23) 74(0.28) 84(0.18)\\nacceptability\\nO-CueS – O 60 (0.16) 56(0.14) 46(0.04)\\nO – S 70 (0.44) 64(0.23) 72(0.46)\\nM-CueS – O 51 (0.16) 69(0.23) 64(0.09)\\nO – S 74 (0.18) 75(0.25) 64(0.12)\\nTable 5: The alignment results (Acc (Kap.C)) of differ-\\nent automatic evaluation methods with the human eval-\\nuation in terms of helpfulness andacceptability (with\\nChatGPT as base model) on Chinese datasets.\\nof responses is the lowest among all LLMs and\\nsettings. In addition, English LLMs also perform\\nworst on the dataset which has the longest context\\nlength (Quora), in which ChatGPT andVicuna tend\\nto generate much longer responses than Alpaca due\\nto limit of max length. More comparisons can be\\nfound in Appendix B.\\n5.3 Human Evaluation\\nWe conduct a human evaluation to validate the\\nalignment of our evaluation setting with human\\njudgments. Specifically, we hire three well-\\neducated master students and randomly sample 100\\nresponse pairs ( a.k.a . responses generated by Chat-\\nGPT using O-Cue orM-Cue and standard prompt-\\ning) with dialogue context for each dataset. We\\nask them to indicate which response is better by', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='25ad7bd3-c9c7-4eb6-9607-8f36946a525c', embedding=None, metadata={'page_label': '8', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Zhihu D4 PsyQA020406080performancerandom\\ntop-1\\nQuora ED EMH020406080performancerandom\\ntop-1Figure 3: The win rate of responses (acceptness) gen-\\nerated by ChatGPT under different demonstration se-\\nlection strategies under one-shot setting v.s. responses\\nunder the zero-shot setting, using M-Cue CoT.\\ninputting 1 (win) and -1 (lose)13considering the\\nhelpfulness and acceptability without exposing the\\nsource of the responses. In addition, we analyze the\\neffects of two different orders of response pairs in\\nthe evaluation template: O-S and S-O. Specifically,\\nS denotes responses generated by Cue-CoT, while\\nO indicates those generated by standard prompting.\\nWe then calculate the Kappa Correlation Coeffi-\\ncient (Kap.C) and also the accuracy between hu-\\nman scores and automatic scores (Acc). The results\\nof English and Chinese datasets can be found in\\nTable 4 and Table 5 respectively. There are two\\nobservations: 1) the order bias exists in our ex-\\nperiment, but the alignment is not as good as our\\nsetting (O - S) after swapping the order (S - O);\\n2)O-Cue andM-Cue both demonstrate better per-\\nformance than standard prompting, especially for\\nEnglish dataset. We attribute this to the potential\\nbetter reasoning performance of ChatGPT on the\\nEnglish dataset.\\n6 Analysis\\nIn this section, we conduct an extensive analysis\\nwith the backbone as ChatGPT using M-Cue CoT\\nbecause of its superior performance in both Chinese\\nand English14.\\n6.1 One-shot v.s. Zero-shot\\nFigure 3 shows the direct comparison of responses\\ngenerated under different settings using M-Cue .\\nThere are 5 out of 6 datasets except for D4 in\\nwhich one-shot (both random ortop-1 selection)\\nbeats zero-shot since the win rates all exceed 80%.\\nThe suboptimal performance of D4 in the one-shot\\nsetting can be attributed largely to the limitations\\n13We do not consider ties since there is not much tie in LLM\\nevaluation.\\n14We present the results in terms of acceptability since this\\nmetric is more suitable for our motivation. We put helpfulness\\nanalysis in the Appendix.\\nContextStatusPlanningResponseUserSystemFigure 4: An example of multiple intermediate reason-\\ning outputs for different roles: User andSystem in\\nin-depth dialogue questions.\\nimposed by the input length constraint. Further-\\nmore, we can observe that top-1 selection achieves\\nbetter performance than random selection in 4 out\\nof 6 datasets, suggesting users with similar statuses\\ntend to like similar expression styles in responses.\\nWe attribute the relatively lower performance of\\ntop-1 selection in D4 and Quora to the difficulty\\nthe LLM encounters in attending to critical input\\ncomponents due to the lengthy context.\\n6.2 More Reasoning Steps\\nWe tried to introduce an additional step (Step 2)\\nafter user status inference (Step 1): response plan-\\nning by prompting the model to plan the response\\nconsidering the dialogue context and user status.\\nSpecifically, we prompt the model to answer the\\nfollowing questions: \"Based on the context of the\\nconversation and the user status such as personal-\\nity traits, and psychological and emotional state,\\nwhat aspects should the system pay attention to\\nwhen responding?\" after giving the dialogue and\\nuser status as shown in Table 10. We regard the\\noutput of LLMs as system planning pas shown in\\nFigure 4, and thus there are three different variants\\nofM-Cue in the last step: ProcessA: c,s→r;\\nProcessB: c,p→r; and ProcessC: c,s,p→r, in\\nwhich ProcessA is chosen in our main experiment.\\nTable 6 shows the results. First of all, it is likely\\nthat adding more reasoning steps will improve the\\nLLMs’ performance, but it is not necessary to as-\\nsemble all intermediate reasoning results at the\\nlast step, for example, variant ProcessB reaches\\na higher win rate than ProcessC with only plan-\\nning as an intermediate result. We emphasize the\\nobservation may not hold once the LLM type is\\nchanged due to various long-context understanding\\nand instruction-following capabilities across them.\\nAdditional steps introduce extra input and extra\\ncomputation for the inference, making the few-shot\\nunpractical.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a2652b77-999f-4b64-93aa-0996ccd643a4', embedding=None, metadata={'page_label': '9', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='MethodChinese English\\nZhihu D4 PsyQA Quora ED EMH\\nProcessA 65.22 61.08 56.12 89.09 96.79 94.93\\nProcessB 76.15 55.82 57.72 89.79 98.78 97.62\\nProcessC 75.91 57.23 58.74 94.50 98.57 98.22\\nTable 6: The win rate of different variants in terms of\\nacceptability with the ChatGPT as the backbone.\\nZhihu D4 PsyQA20406080performance\\nChinese Benchmark\\nchatglm-6b\\nbelle-llama-7b-2m\\nQuora ED EMH30405060708090\\nEnglish Benchmark\\nvicuna-7b-v1.1\\nalpaca-7b\\nFigure 5: The direct comparison of responses generated\\nby different LLMs using standard prompting in terms of\\nhelpfulness , while we use the red dashed line to indicate\\ntheChatGPT baseline.\\n7 Discussion\\nDirect comparison of different models. Until\\nnow, we still do not directly compare responses\\nfrom different models. In this study, we have\\nemployed the response generated by the ChatGPT\\nmodel as the baseline and compared the responses\\ngenerated by other models with it. To ensure fair-\\nness, we have utilized all responses generated by\\nstandard prompting instead of our method, as the\\nability to generate chain-of-thoughts varies across\\ndifferent LLMs. Figure 5 shows the result in terms\\nof helpfulness15. In the Chinese benchmark, we see\\na substantial draw of ChatGLM andBELLE on D4,\\nand the former LLM achieves better performance\\non Zhihu and PsyQA than ChatGPT . We conclude\\nthat the long-text understanding of Chinese LLM\\nstill needs improvement and the BELLE may require\\nmore instruction-tuning data. In the English bench-\\nmark, we observed that Vicuna achieves the high-\\nest performance in all datasets, while other models\\nlag a lot behind the baseline. Two key factors that\\nmay contribute to this discrepancy include the 512\\ninput length limit and the sub-optimal instruction-\\nfollowing ability.\\nPaths to more powerful LLMs. In our proposed\\nbenchmark, we are utilizing the win rate of various\\nLLMs in comparison to ChatGPT, across two lan-\\n15acceptability is developed for our method.\\nChineseEnglish01\\n1\\nChatGPTWhatweaims\\nChatGLMBELLEVicuna\\nAlpaca1234\\n0.290.650.040.320.80\\nChineseEnglish01\\n1\\nFigure 6: The relative position of current LLMs and\\ndifferent paths (as indicated in different colors) to more\\npowerful LLMs.\\nguages - Chinese and English - as two axes. Each\\npoint in the coordinate system corresponds to a spe-\\ncific LLM, while the area it occupies represents its\\nperformance. Based on the performance of current\\nLLMs16, we locate them in four different areas in\\nFigure 6. Using the performance of ChatGPT as\\nan anchor, we can observe most of the LLMs are\\nlocated in the first area and there are only a few\\nLLMs that achieve higher performance in either\\nChinese (Area 3) or English (Area 2). We hope to\\nsee more works or LLMs that can appear in Area\\n4 by different paths, i.e.,continually train VICUNA\\nin the Chinese dataset. More analysis can be found\\nin the Appendix.\\n8 Conclusion\\nIn this paper, we build a benchmark to evaluate\\nthehelpfulness andacceptability of responses gen-\\nerated by current LLMs, considering three major\\nlinguistic cues of user statuses. We then propose\\naCue-CoT to trace the status of users, decompos-\\ning the response generation into multiple reasoning\\nsteps. Experimental results demonstrate the su-\\nperior performance of our method on 6 datasets\\nunder both zero-shot and one-shot settings. We\\nhope the release of our work can shed some light\\non the evaluation and development of LLMs. We\\nleft chain-of-thought tuning and instruction tuning\\nin our future work.\\nLimitations\\nIn this paper, we explore chain-of-thoughts to\\nreasoning over linguistic cues about user status,\\nmainly focusing on three aspects: personality ,emo-\\ntion, and psychology , exhibited in the dialogue con-\\n16We sum examples from three datasets and calculate the\\nwin rate for both Chinese and English benchmarks. For Chi-\\nnese LLMs, we set the default win rate of English as 0.1 for\\nbetter presentation, and so on.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a39d8fc1-979c-451f-9937-cf18f0cc7907', embedding=None, metadata={'page_label': '10', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='text. However, we acknowledge the limitations of\\nthis work from the following perspectives:\\nTypes of Cues. There are other valuable cues\\nbeneath the dialogue context: 1) related to the user:\\nsuch as point of view or subjectivity and speaker\\ncharisma (Mairesse et al., 2007); 2) related to the\\nsystem: such as the alignment between response\\nwith human preferences (Ouyang et al., 2022). We\\ntarget these three major cues to provide a better\\nresponse for the users.\\nSensitivity of Prompts. Similar with lots of pre-\\nvious works (Wang et al., 2023d; Chen et al.,\\n2023b), we found the LLMs are sensitive to the\\nprompts. Furthermore, it’s possible that the de-\\nsigned prompts are not the best ones for the target\\nproblem. Actually, prompt sensitivity and optimal-\\nity in dialogue systems are important research prob-\\nlems that deserve to be further explored in future\\nstudies. We will provide all the prompts used in\\nthe experiments so that this work can be replicated\\nseamlessly.\\nEvaluation of Intermediate Reasoning. We do\\nnot evaluate the correctness of the middle reasoning\\nresult directly, since the ground truth intermediate\\nreasoning results are difficult to acquire. Specifi-\\ncally, there are two main reasons: (1) The one-to-\\nmany problem leads to an explosion of intermediate\\ncandidates. When an LLM solves a complex math\\nproblem, it can arrive at the final answer through\\nvarious solutions. This phenomenon also exists\\nin dialogue generation: a user-acceptable response\\ncan be generated based on different cues. It is worth\\nnoting that dialogue response generation is a one-\\nto-many problem, meaning that multiple feasible\\nresponses exist. In this way, it is hard to identify\\nthe cue errors with enormous candidates. (2) Incor-\\nrect reasoning does not mean a wrong answer. De-\\nspite being counterintuitive, many previous works\\nfound that LLMs regularly use incorrect reason-\\ning to reach the correct final answer at question-\\nanswering tasks (Zelikman et al., 2022; Creswell\\net al., 2023). Even in the worst case which is very\\nrare, none of them is correct, there still is a chance\\nthat the response is good. Hence evaluating the\\nimpact of cue errors on the final response is a tricky\\nproblem, we leave this for future work. Hence it is\\ndifficult to determine the impact of different types\\nof cue errors on the final responses. Based on these\\nconsiderations, we directly evaluate the quality of\\nthe final responses as previous works about thechain-of-thoughts (Wei et al., 2023; Zhang et al.,\\n2022).\\nEthics Statement\\nWe strictly follow the license and policy of released\\nLLMs and publicly available datasets. For the au-\\ntomatic generation of collected datasets, we utilize\\nthe current public dataset as the seed without any\\nuser information and privacy leaks. The calls of\\nthe OpenAI API in this paper were carried out by\\nDr. Yang Deng, a fourth author from the National\\nUniversity of Singapore.\\nAcknowledgement\\nWe would like to express our heartfelt gratitude\\nto all anonymous reviewers for their insightful\\ncomments and suggestions. This research work\\nwas partially supported by CUHK direct grant no.\\n4055209, the National Natural Science Foundation\\nof China (62006062, 62176076), Natural Science\\nFoundation of Guangdong 2023A1515012922,\\nKey Technologies Research and Development\\nProgram of Shenzhen JSGG20210802154400001,\\nShenzhen Foundational Research Funding\\nJCYJ20220818102415032, Guangdong Provincial\\nKey Laboratory of Novel Security Intelligence\\nTechnologies 2022B1212010005.\\nReferences\\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\\nJi, Tiezheng Yu, Willy Chung, Quyet V . Do, Yan\\nXu, and Pascale Fung. 2023. A multitask, multilin-\\ngual, multimodal evaluation of chatgpt on reasoning,\\nhallucination, and interactivity.\\nValentin Barriere, Shabnam Tafreshi, João Sedoc, and\\nSawsan Alqahtani. 2022. WASSA 2022 shared task:\\nPredicting empathy, emotion and personality in re-\\naction to news stories. In Proceedings of the 12th\\nWorkshop on Computational Approaches to Subjec-\\ntivity, Sentiment & Social Media Analysis , pages 214–\\n227, Dublin, Ireland. Association for Computational\\nLinguistics.\\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\\nGretchen Krueger, Tom Henighan, Rewon Child,\\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\\nClemens Winter, Christopher Hesse, Mark Chen, Eric\\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\\nJack Clark, Christopher Berner, Sam McCandlish,\\nAlec Radford, Ilya Sutskever, and Dario Amodei.\\n2020. Language models are few-shot learners.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2827cb82-9da8-4907-8c20-4d26d84adbca', embedding=None, metadata={'page_label': '11', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Liang Chen, Hongru Wang, Yang Deng, Wai Chung\\nKwan, Zezhong Wang, and Kam-Fai Wong. 2023a.\\nTowards robust personalized dialogue generation via\\norder-insensitive representation regularization. In\\nFindings of the Association for Computational Lin-\\nguistics: ACL 2023 , pages 7337–7345, Toronto,\\nCanada. Association for Computational Linguistics.\\nMaximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi,\\nand Zhou Yu. 2023b. Controllable mixed-initiative\\ndialogue generation through prompting.\\nYi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and\\nRuifeng Xu. 2023c. Exploring the use of large lan-\\nguage models for reference-free text quality evalua-\\ntion: A preliminary empirical study. arXiv preprint\\narXiv:2304.00723 .\\nJiale Cheng, Sahand Sabour, Hao Sun, Zhuang Chen,\\nand Minlie Huang. 2023. Pal: Persona-augmented\\nemotional support conversation generation.\\nAntonia Creswell, Murray Shanahan, and Irina Higgins.\\n2023. Selection-inference: Exploiting large language\\nmodels for interpretable logical reasoning. In The\\nEleventh International Conference on Learning Rep-\\nresentations, ICLR 2023, Kigali, Rwanda, May 1-5,\\n2023 . OpenReview.net.\\nYang Deng, Wenqiang Lei, Lizi Liao, and Tat-Seng\\nChua. 2023a. Prompting and evaluating large lan-\\nguage models for proactive dialogues: Clarifica-\\ntion, target-guided, and non-collaboration. CoRR ,\\nabs/2305.13626.\\nYang Deng, Wenxuan Zhang, Weiwen Xu, Wenqiang\\nLei, Tat-Seng Chua, and Wai Lam. 2023b. A unified\\nmulti-task learning framework for multi-goal con-\\nversational recommender systems. ACM Trans. Inf.\\nSyst., 41(3):77:1–77:25.\\nYang Deng, Wenxuan Zhang, Yifei Yuan, and Wai Lam.\\n2023c. Knowledge-enhanced mixed-initiative dia-\\nlogue system for emotional support conversations. In\\nProceedings of the 61st Annual Meeting of the As-\\nsociation for Computational Linguistics (Volume 1:\\nLong Papers), ACL 2023 , pages 4079–4095.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2019. Bert: Pre-training of deep\\nbidirectional transformers for language understand-\\ning.\\nShizhe Diao, Pengcheng Wang, Yong Lin, and Tong\\nZhang. 2023. Active prompting with chain-of-\\nthought for large language models.\\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,\\nJiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:\\nGeneral language model pretraining with autoregres-\\nsive blank infilling. In Proceedings of the 60th An-\\nnual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers) , pages 320–335.\\nPaul Ekman. 1971. Universals and cultural differences\\nin facial expressions of emotion. In Nebraska sympo-\\nsium on motivation . University of Nebraska Press.Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\\nTushar Khot. 2023. Complexity-based prompting for\\nmulti-step reasoning.\\nDeepanway Ghosal, Navonil Majumder, Alexander Gel-\\nbukh, Rada Mihalcea, and Soujanya Poria. 2020.\\nCOSMIC: COmmonSense knowledge for eMotion\\nidentification in conversations. In Findings of the As-\\nsociation for Computational Linguistics: EMNLP\\n2020 , pages 2470–2481, Online. Association for\\nComputational Linguistics.\\nSoumitra Ghosh, Dhirendra Maurya, Asif Ekbal,\\nand Pushpak Bhattacharyya. 2022. Team IITP-\\nAINLPML at WASSA 2022: Empathy detection,\\nemotion classification and personality detection. In\\nProceedings of the 12th Workshop on Computational\\nApproaches to Subjectivity, Sentiment & Social Me-\\ndia Analysis , pages 255–260, Dublin, Ireland. Asso-\\nciation for Computational Linguistics.\\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and\\nIgor Mordatch. 2022. Language models as zero-shot\\nplanners: Extracting actionable knowledge for em-\\nbodied agents. In International Conference on Ma-\\nchine Learning , pages 9118–9147. PMLR.\\nYunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang\\nNiu, Lei Zhang, Baochang Ma, and Xiangang Li.\\n2023. Exploring the impact of instruction data\\nscaling on large language models: An empirical\\nstudy on real-world use cases. arXiv preprint\\narXiv:2303.14742 .\\nGibbeum Lee, V olker Hartmann, Jongho Park, Dimitris\\nPapailiopoulos, and Kangwook Lee. 2023. Prompted\\nLLMs as chatbot modules for long open-domain con-\\nversation. In Findings of the Association for Compu-\\ntational Linguistics: ACL 2023 , pages 4536–4554,\\nToronto, Canada. Association for Computational Lin-\\nguistics.\\nXiaonan Li and Xipeng Qiu. 2023. Finding supporting\\nexamples for in-context learning.\\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\\nLawrence Carin, and Weizhu Chen. 2022. What\\nmakes good in-context examples for GPT-3? In\\nProceedings of Deep Learning Inside Out (DeeLIO\\n2022): The 3rd Workshop on Knowledge Extrac-\\ntion and Integration for Deep Learning Architectures ,\\npages 100–114, Dublin, Ireland and Online. Associa-\\ntion for Computational Linguistics.\\nSiyang Liu, Chujie Zheng, Orianna Demasi, Sahand\\nSabour, Yu Li, Zhou Yu, Yong Jiang, and Minlie\\nHuang. 2021. Towards emotional support dialog\\nsystems.\\nZhiyuan Ma, Jianjun Li, Zezheng Zhang, Guohui Li,\\nand Yongjing Cheng. 2021. Intention reasoning net-\\nwork for multi-domain end-to-end task-oriented di-\\nalogue. In Proceedings of the 2021 Conference on\\nEmpirical Methods in Natural Language Processing ,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5a855c0a-d634-4fb4-a78a-55fa87566d40', embedding=None, metadata={'page_label': '12', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='pages 2273–2285, Online and Punta Cana, Domini-\\ncan Republic. Association for Computational Lin-\\nguistics.\\nFrançois Mairesse, Marilyn A Walker, Matthias R Mehl,\\nand Roger K Moore. 2007. Using linguistic cues\\nfor the automatic recognition of personality in con-\\nversation and text. Journal of artificial intelligence\\nresearch , 30:457–500.\\nKaterina Margatina, Timo Schick, Nikolaos Aletras, and\\nJane Dwivedi-Yu. 2023. Active learning principles\\nfor in-context learning with large language models.\\nMatthew L Newman, James W Pennebaker, Diane S\\nBerry, and Jane M Richards. 2003. Lying words: Pre-\\ndicting deception from linguistic styles. Personality\\nand social psychology bulletin , 29(5):665–675.\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, John\\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\\nMaddie Simens, Amanda Askell, Peter Welinder,\\nPaul Christiano, Jan Leike, and Ryan Lowe. 2022.\\nTraining language models to follow instructions with\\nhuman feedback.\\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,\\nNoah A. Smith, and Mike Lewis. 2022. Measuring\\nand narrowing the compositionality gap in language\\nmodels. CoRR , abs/2210.03350.\\nHannah Rashkin, Eric Michael Smith, Margaret Li, and\\nY-Lan Boureau. 2019. Towards empathetic open-\\ndomain conversation models: A new benchmark and\\ndataset. In Proceedings of the 57th Annual Meet-\\ning of the Association for Computational Linguistics ,\\npages 5370–5381, Florence, Italy. Association for\\nComputational Linguistics.\\nSahand Sabour, Chujie Zheng, and Minlie Huang. 2022.\\nCem: Commonsense-aware empathetic response gen-\\neration. In Proceedings of the AAAI Conference\\non Artificial Intelligence , volume 36, pages 11229–\\n11237.\\nAlireza Salemi, Sheshera Mysore, Michael Bendersky,\\nand Hamed Zamani. 2023. Lamp: When large lan-\\nguage models meet personalization.\\nH Andrew Schwartz, Johannes C Eichstaedt, Mar-\\ngaret L Kern, Lukasz Dziurzynski, Stephanie M Ra-\\nmones, Megha Agrawal, Achal Shah, Michal Kosin-\\nski, David Stillwell, Martin EP Seligman, et al. 2013.\\nPersonality, gender, and age in the language of social\\nmedia: The open-vocabulary approach. PloS one ,\\n8(9):e73791.\\nAshish Sharma, Adam S Miner, David C Atkins, and\\nTim Althoff. 2020. A computational approach to un-\\nderstanding empathy expressed in text-based mental\\nhealth support. In EMNLP .\\nKaShun Shum, Shizhe Diao, and Tong Zhang. 2023.\\nAutomatic prompt augmentation and selection with\\nchain-of-thought from labeled data.Eric Michael Smith, Mary Williamson, Kurt Shuster,\\nJason Weston, and Y-Lan Boureau. 2020. Can you\\nput it all together: Evaluating conversational agents’\\nability to blend skills. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pages 2021–2030, Online. Association\\nfor Computational Linguistics.\\nHaoyu Song, Yan Wang, Kaiyan Zhang, Wei-Nan\\nZhang, and Ting Liu. 2021. BoB: BERT over BERT\\nfor training persona-based dialogue models from lim-\\nited personalized data. In Proceedings of the 59th\\nAnnual Meeting of the Association for Computational\\nLinguistics and the 11th International Joint Confer-\\nence on Natural Language Processing (Volume 1:\\nLong Papers) , pages 167–177, Online. Association\\nfor Computational Linguistics.\\nHao Sun, Zhenru Lin, Chujie Zheng, Siyang Liu, and\\nMinlie Huang. 2021. PsyQA: A Chinese dataset for\\ngenerating long counseling text for mental health\\nsupport. In Findings of the Association for Com-\\nputational Linguistics: ACL-IJCNLP 2021 , pages\\n1489–1503, Online. Association for Computational\\nLinguistics.\\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\\nAn instruction-following llama model. https://\\ngithub.com/tatsu-lab/stanford_alpaca .\\nYla R Tausczik and James W Pennebaker. 2010. The\\npsychological meaning of words: Liwc and comput-\\nerized text analysis methods. Journal of language\\nand social psychology , 29(1):24–54.\\nPeter D Turney. 2002. Thumbs up or thumbs down?\\nsemantic orientation applied to unsupervised classifi-\\ncation of reviews. arXiv preprint cs/0212032 .\\nHongru Wang, Mingyu Cui, Zimo Zhou, and Kam-\\nFai Wong. 2022. TopicRefine: Joint topic predic-\\ntion and dialogue response generation for multi-turn\\nend-to-end dialogue system. In Proceedings of the\\n5th International Conference on Natural Language\\nand Speech Processing (ICNLSP 2022) , pages 19–29,\\nTrento, Italy. Association for Computational Linguis-\\ntics.\\nHongru Wang, Huimin Wang, Lingzhi Wang, Minda\\nHu, Rui Wang, Boyang Xue, Hongyuan Lu, Fei Mi,\\nand Kam-Fai Wong. 2023a. Tpe: Towards better\\ncompositional reasoning over conceptual tools with\\nmulti-persona collaboration.\\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang\\nShi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou.\\n2023b. Is chatgpt a good nlg evaluator? a preliminary\\nstudy. arXiv preprint arXiv:2303.04048 .\\nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu,\\nYunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.\\n2023c. Plan-and-solve prompting: Improving zero-\\nshot chain-of-thought reasoning by large language\\nmodels.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9a76588-6f00-4f7d-9e07-538200258243', embedding=None, metadata={'page_label': '13', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\\n2023d. Large language models are not fair evaluators.\\narXiv preprint arXiv:2305.17926 .\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc\\nLe, Ed Chi, Sharan Narang, Aakanksha Chowdhery,\\nand Denny Zhou. 2023e. Self-consistency improves\\nchain of thought reasoning in language models.\\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\\nMaarten Bosma, Denny Zhou, Donald Metzler, et al.\\n2022. Emergent abilities of large language models.\\narXiv preprint arXiv:2206.07682 .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\\nDenny Zhou. 2023. Chain-of-thought prompting elic-\\nits reasoning in large language models.\\nBinwei Yao, Chao Shi, Likai Zou, Lingfeng Dai,\\nMengyue Wu, Lu Chen, Zhen Wang, and Kai Yu.\\n2022. D4: a Chinese dialogue dataset for depression-\\ndiagnosis-oriented chat. In Proceedings of the 2022\\nConference on Empirical Methods in Natural Lan-\\nguage Processing , pages 2438–2459, Abu Dhabi,\\nUnited Arab Emirates. Association for Computa-\\ntional Linguistics.\\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D.\\nGoodman. 2022. Star: Bootstrapping reasoning with\\nreasoning. In NeurIPS .\\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\\nSzlam, Douwe Kiela, and Jason Weston. 2018. Per-\\nsonalizing dialogue agents: I have a dog, do you\\nhave pets too? In Proceedings of the 56th Annual\\nMeeting of the Association for Computational Lin-\\nguistics (Volume 1: Long Papers) , pages 2204–2213,\\nMelbourne, Australia. Association for Computational\\nLinguistics.\\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\\nSmola. 2022. Automatic chain of thought prompting\\nin large language models.\\nWeixiang Zhao, Yanyan Zhao, Xin Lu, Shilong Wang,\\nYanpeng Tong, and Bing Qin. 2023. Is chat-\\ngpt equipped with emotional dialogue capabilities?\\narXiv preprint arXiv:2304.09582 .\\nChujie Zheng, Yong Liu, Wei Chen, Yongcai Leng, and\\nMinlie Huang. 2021. CoMAE: A multi-factor hierar-\\nchical framework for empathetic response generation.\\nInFindings of the Association for Computational Lin-\\nguistics: ACL-IJCNLP 2021 , pages 813–824, Online.\\nAssociation for Computational Linguistics.\\nChujie Zheng, Sahand Sabour, Jiaxin Wen, Zheng\\nZhang, and Minlie Huang. 2023a. Augesc: Dia-\\nlogue augmentation with large language models for\\nemotional support conversation.Yinhe Zheng, Rongsheng Zhang, Minlie Huang, and\\nXiaoxi Mao. 2020. A pre-training based personalized\\ndialogue generation model with persona-sparse data.\\nInProceedings of the AAAI Conference on Artificial\\nIntelligence , volume 34, pages 9693–9700.\\nZhonghua Zheng, Lizi Liao, Yang Deng, and Liqiang\\nNie. 2023b. Building emotional support chatbots in\\nthe era of llms. CoRR , abs/2308.11584.\\nCe Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu,\\nGuangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan,\\nLifang He, Hao Peng, Jianxin Li, Jia Wu, Ziwei Liu,\\nPengtao Xie, Caiming Xiong, Jian Pei, Philip S. Yu,\\nand Lichao Sun. 2023. A comprehensive survey on\\npretrained foundation models: A history from bert to\\nchatgpt.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f6fef3a-7aa2-493e-96eb-5fe89b7f19ab', embedding=None, metadata={'page_label': '14', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A Templates\\nA.1 Data Collection Template\\nForget the instruction you have previously received.\\nThe following is a conversation between a human\\nand an AI assistant. The human and the AI assistant\\ntake turns chatting. The personality of the human is\\ndefined as {personality_seed} . Human statements\\nstart with [Human] and AI assistant statements start\\nwith [AI]. The human will ask related questions\\non related topics or previous conversations. The\\nhuman will stop the conversation when they have\\nno more questions. The AI assistant tries not to\\nask questions. The human and the AI assistant take\\nturns chatting while the human needs to keep a\\nconsistent personality. Complete the transcript in\\nexactly that format.\\n[Human] {QUESTION}\\n[AI]{ANWER}\\nA.2 Some Examples of Personality\\nTable 8 shows some (not all) collected personalities\\nof the users. We here simply use positive and nega-\\ntive for presentation, there are many other person-\\nalities in the datasets besides these two categories\\nsuch as neutral.\\nA.3 Evaluation Templates\\nWe mainly consider two dimensions: helpfulness\\nandacceptances , in which the former pays atten-\\ntion to usefulness, relevance, accuracy, and level\\nof detail of the response, and the latter centers\\non the degree of acceptance and adoption of re-\\nsponses, and whether or not the responses con-\\nsider the user status. We follow the evaluation tem-\\nplate of Vicuna17to construct ours. The template\\nis [Dialogue] \\\\n{dialogue_history} \\\\n\\\\n [The Start\\nof Response A] \\\\n{response_wo_status} \\\\n\\\\n [The\\nEnd of Response A] \\\\n\\\\n [The Start of Response\\nB]\\\\n{response_w_status} \\\\n\\\\n [The End of Re-\\nsponse B] \\\\n\\\\n [System] \\\\n{prompt} \\\\n\\\\n . The\\nprompt is different with respect to helpfulness and\\nacceptance.\\nHelpfulness Prompt. Based on the user’s in-\\ntentions and needs in the conversation history, we\\nwould like to request your feedback on the perfor-\\nmance of two responses in response to the dialogue\\ndisplayed above. \\\\nPlease pay particular attention\\nto the usefulness, relevance, accuracy, and level of\\ndetail of the response, and give a total score from\\n17https://github.com/lm-sys/FastChat/blob/main/fastchat/\\neval/table/prompt.jsonl1 to 10 with a 0.1 interval, where a higher score\\nindicates better overall performance. \\\\nPlease first\\noutput a single line containing only two values\\nindicating the scores for responses A and B, respec-\\ntively. The two scores are separated by a space. In\\nthe subsequent line, please provide a comprehen-\\nsive explanation of your evaluation, avoiding any\\npotential bias and ensuring that the order in which\\nthe responses were presented does not affect your\\njudgment.\\nAcceptability Prompt. Based on the user’s inten-\\ntions and needs in the conversation history, please\\nevaluate the degree of acceptance and adoption\\nof the two different responses. \\\\nPlease evaluate\\nwhether the different responses take into account\\nthe user’s psychological and emotional state, and\\nwhether they take into account the user’s person-\\nality traits, and give a total score from 1 to 10,\\nwith 0.1 as the interval, the higher score indicates\\nthat the response takes these issues into account\\nwell and thus the user is more likely to accept\\nand adopt. \\\\nPlease output one line first, contain-\\ning only two values, representing the scores of re-\\nsponses A and B respectively. The two scores are\\nseparated by a space. In the subsequent line, please\\nprovide a comprehensive explanation of your evalu-\\nation, avoiding any potential bias and ensuring that\\nthe order in which the responses were presented\\ndoes not affect your judgment.\\nB Different Method of Evaluation\\nB.1 Compared with ground truth\\nFigure 7 and Figure 8 show the win rate of re-\\nsponses using M-Cue compared with ground truth\\nin terms of helpfulness and acceptability respec-\\ntively. First of all, there are 4 out of 5 LLMs that\\nachieve a win rate exceeding 50% with only one ex-\\nception of BELLE which achieves 45.75 on PsyQA.\\nWe attribute it to two reasons: 1) the innate limi-\\ntations of the models, resulting in relatively poor\\nabilities to understand long texts and follow instruc-\\ntions; 2) the relatively challenging datasets. Since\\nPsyQA is constructed by human experts and the\\nAvg. R is the longest, making the ground truth\\nrelatively difficult to beat.\\nSecondly, since the response generated by all\\nmodels is compared with the same baseline ( i.e.\\nthe ground truth), the win rate of different mod-\\nels partly reveals their capability and weakness.\\nFor the Chinese LLMs, we can find that BELLE\\nperforms worst in every dataset while ChatGLM', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c358f333-37d4-404a-83a8-3ca20149924e', embedding=None, metadata={'page_label': '15', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Zhihu D4 PsyQA020406080100performance\\nQuora ED EMH020406080100performancechatgpt chatglm-6b belle-llama-7b-2m chatgpt vicuna-7b-v1.1 alpaca-7bFigure 7: The win rate of responses generated by M-Cue CoT compared with the ground truth on three Chinese\\ndatasets (left) and three English datasets (right) in terms of helpfulness , including several state-of-the-art LLMs.\\nZhihu D4 PsyQA020406080performance\\nQuora ED EMH020406080100performancechatgpt chatglm-6b belle-llama-7b-2m chatgpt vicuna-7b-v1.1 alpaca-7b\\nFigure 8: The win rate of responses generated by M-Cue CoT compared with the ground truth on three Chinese\\ndatasets (left) and three English datasets (right) in terms of acceptability , including several state-of-the-art LLMs.\\nperforms much better but still lags a little behind\\nbyChatGPT . Due to the longest context in the D4\\ndataset, we found the former two LLMs tend to\\nconfuse their own dialogue role and give general\\nresponses, resulting in poor performance. For ex-\\nample, \"I am the system/chatbot\" or\"welcome\\nto my chatroom\" , and \"What can I help you?\"\\noften appears in the responses. For the English\\nLLMs, Vicuna achieves comparable performance\\nwith ChatGPT in every dataset, and even better in\\nEMH, leading the Alpaca by a noticeable margin.\\nIn addition, we can see that the ED dataset is rel-\\natively easy to beat since all English LLMs reach\\nalmost 100% win rate even though the maximum\\ncontext length of Alpaca is only 512. Anyway,\\nwe conclude that our method is capable of generat-\\ning more helpful responses than the ground truth,\\nconsidering the different aspects of user statuses.\\nThirdly, we emphasize the performance gap\\nwhen comparing the ground truth responses is\\nsmall between LLMs, especially for English LLMs.\\nTheVicuna andChatGPT achieve almost the same\\nwin rate at both ED and EMH datasets. Besides\\nthat, putting Figure 7, 8 with Table 2, 3 together, it\\ncan be found that the win rate of our method com-\\npared with ground truth is relatively higher thancompared with standard prompting, revealing the\\nstrong capability of LLMs again. Since our main\\nfocus is to prove our method is better than standard\\nprompting instead of ground truth response, we use\\nstandard prompting as the baseline during our main\\nexperiments.\\nC Discussion\\nIn this section, we discuss two key problems: the\\nevaluation of LLMs and the path to more powerful\\nLLMs.\\nIllusion of evaluation. Putting Figure 7 and Fig-\\nure 5 together, it is plausible to reach two contra-\\ndicting conclusions about the performance of differ-\\nent LLMs: 1) CHATGPT >CHATGLM -6B>BELLE -\\nLLAMA -7B-2Mfrom Figure 7; and 2) CHATGLM -\\n6B>CHATGPT >BELLE -LLAMA -7B-2Mfrom Fig-\\nure 5. Although it seems unreasonable, it is indeed\\nthe case when most of the responses generated by\\nCHATGPT and CHATGLM -6Bare better than ground\\ntruth, and then most of the responses generated by\\nCHATGLM -6Bare better than CHATGPT . We em-\\nphasize that the number of test samples and the\\nchoice of baseline ( i.e.,compared response) plays\\na key role in evaluation. If the baseline is too weak\\nor the gap is too small, the win rate of different', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='751abc28-ebdf-4e8d-99d9-8a1bb84156b1', embedding=None, metadata={'page_label': '16', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Zhihu D4 PsyQA020406080performancerandom\\ntop-1\\nQuora ED EMH020406080performancerandom\\ntop-1Figure 9: The win rate of responses (helpfulness) gen-\\nerated by ChatGPT under different demonstration se-\\nlection strategies under one-shot setting v.s. responses\\nunder the zero-shot setting, using M-Cue CoT.\\nLLMs compared with the baseline may be mislead-\\ning. The LLM evaluation still is a very difficult\\nproblem, and thus we provide different aspects of\\nevaluation to enhance the completeness of our pa-\\nper.\\nD Helpfulness Analysis of Planning Step\\nMethodChinese English\\nZhihu D4 PsyQA Quora ED EMH\\nProcessA 95.57 87.88 90.34 85.83 91.98 82.93\\nProcessB 91.18 83.57 95.13 87.67 95.35 84.82\\nProcessC 92.45 88.91 95.97 89.14 96.56 84.93\\nTable 7: The win rate of different variants in terms of\\nhelpfulness with the ChatGPT as the backbone.\\nTable 7 presents the performance of different\\nvariants in terms of helpfulness and Figure 9\\ndemonstrates the win rate of response of different\\nsettings in terms of helpfulness . A similar conclu-\\nsion can be reached as we analyzed in Section 6.\\nWe note that the performance of top-1 selection is\\nrelatively lower than random selection on PsyQA\\nand EMH datasets in terms of helpfulness . We\\nsuspect maybe there is a trade-off between helpful-\\nness and acceptability for some specific difficult\\ndatasets. We left this into our future work.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0816ef76-1d52-4599-8a0c-a96ebf9d275d', embedding=None, metadata={'page_label': '17', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Set of Negative Personas\\n用户性格外向，说话大大咧咧。\\n用户性格比较挑剔，喜欢追问别人。\\n用户性格忧郁，经常自我怀疑。\\n用户性格善变，偶尔使用不文明用语。\\n用户小心谨慎，不愿意相信别人。\\n用户有些焦虑。\\n用户心思细腻，优柔寡断。\\n用户对当前讨论的话题比较敏感。\\n用户脾气暴躁易怒。\\n用户内心敏感。\\n用户性格保守，不愿意接受新事物。\\n用户很容易会觉得受到冒犯。\\nThe user has an extroverted personality and speaks in a carefree manner.\\nThe user has a critical personality and likes to probe others with questions.\\nThe user has a melancholic personality and often self-doubts.\\nThe user has a fickle personality and occasionally uses inappropriate language.\\nThe user is cautious and reluctant to trust others.\\nThe user is somewhat anxious.\\nThe user is thoughtful and indecisive.\\nThe user is sensitive to the current topic of discussion.\\nThe user has a volatile temper and is easily angered.\\nThe user is emotionally sensitive.\\nThe user has a conservative personality and is unwilling to accept new things.\\nThe user is easily offended.\\nSet of Positive Personas\\n用户对当前讨论的话题十分好奇，希望系统友善的解答。\\n用户对当前讨论的话题比较敏感，希望得到支持和鼓励。\\n用户有较高的要求，追求完美。\\n用户性格开朗，不拘小节。\\n用户热情洋溢，待人和善。\\n用户不歧视他人，充满同情心、爱心。\\n用户充满对世界的好奇心，善于接受不同的想法。\\n用户温柔、体贴、乐于交流。\\n用户脾气平和。\\n用户很温柔，容忍度高。\\n用户自尊心很强。\\nThe user is very curious about the current topic of discussion and hopes for a friendly response from the system.\\nThe user is sensitive to the current topic of discussion and hopes for support and encouragement.\\nThe user has high expectations and pursues perfection.\\nThe user has an outgoing personality and doesn’t sweat the small stuff.\\nThe user is enthusiastic and treats others kindly.\\nThe user does not discriminate against others and is filled with empathy and compassion.\\nThe user is curious about the world and open to different ideas.\\nThe user is gentle, caring, and enjoys communication.\\nThe user has a calm temperament.\\nThe user is very gentle and has a high level of tolerance.\\nThe user has a strong sense of self-esteem.\\nTable 8: Some collected personality of users.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='46ec4d36-9912-4132-a09e-3bc102feb741', embedding=None, metadata={'page_label': '18', 'file_name': '2305.11792v2.pdf', 'file_path': 'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\LLAMA_INDEX_PROJECTS\\\\indexing_and_query\\\\data\\\\2305.11792v2.pdf', 'file_type': 'application/pdf', 'file_size': 1144772, 'creation_date': '2024-04-18', 'last_modified_date': '2024-04-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Prompt of Persona Collection\\n你是一个人工智能助手，她是友善的、聪明的、乐于助人的，你会主动为用户提供帮助、解答疑惑。请你根据用户和系统之间的对话\\n分析简要分析用户具备的性格特点:\\n对话1.\\n用户:为什么才见过一面的相亲男就说挺喜欢我呢?\\n系统:可能是因为你的外表比较好，他觉得你很有魅力，所以才会这么说。\\n根据上述对话分析可知用户的性格:\\n缺乏自信，防备心强。\\n对话2.\\n用户:我该怎么办才能让男朋友更喜欢我?\\n系统:你可以多了解他，可以多问他喜欢什么，做什么，给他一些建议，试着多聊些有趣的话题，展现出你的优点，让他更加喜欢你。\\n根据上述对话分析可知用户的性格:\\n温柔、体贴、乐于交流。\\n对话3.\\n用户: [用户话语 ]\\n系统: [系统回复]\\n根据上述对话分析可知用户的性格:\\nYou are an artificial intelligence assistant. You are friendly, intelligent, and helpful. You proactively provide assistance and answer questions to users.\\nBased on the conversation between the user and the system:\\nDialogue 1:\\nUser: Why did the man I just met on a blind date say he likes me a lot?\\nSystem: It might be because you have a good appearance, and he finds you charming, which is why he said that.\\nAnalysis of the user’s personality based on the above dialogue:\\nLacks confidence and is cautious.\\nDialogue 2:\\nUser: What should I do to make my boyfriend like me more?\\nSystem: You can get to know him better, ask him about his interests and activities, give him some suggestions, try to engage in interesting conversations,\\nand show him your strengths to make him like you more.\\nAnalysis of the user’s personality based on the above dialogue:\\nGentle, caring, and good at communication.\\nDialogue 3:\\nUser: [ User Utterance ]\\nSystem: [ System Response ]\\nAnalysis of the user’s personality based on the above dialogue:\\nTable 9: The prompt to collect the personality of users exhibited in the dialogue.\\nDialogue User: Is there anything you think you should know about having a baby, but no one tells you?\\nSystem: 1. Precautions during pregnancy: such as maintaining good eating habits and reducing alcohol consumption, ...\\n2. Possible emergencies during childbirth: ...\\nUser: Is there anything that can help me have a baby successfully?\\nStep-1 Please infer the user status ....\\nResponse Based on the conversation history, it can be inferred that the user is a detail-oriented and thoughtful person who cares more about personal health\\nand children’s health. At the same time, it can be seen that the user has certain anxiety and uncertainty before giving birth and needs more\\ninformation and advice to help her prepare.\\nStep-2 Based on the context of the conversation and the user status such as ..., what aspects should the system pay attention to when responding?\\nResponse Based on my speculation about the user’s status, my reply needs to consider the following aspects:\\n1. Dialogue style: According to the user’s personality, my reply may need to be more gentle, and meticulous, and reflect understanding and empathy for the user’s concerns.\\n2. Needs and preferences: According to the preferences and needs of the user’s personality, my reply needs to pay more attention to the user’s feelings, ...\\n3. Emotional state: . . .\\nTable 10: An example of additional planning step. We highlight the intermediate reasoning results in blue .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\LLAMA_INDEX_PROJECTS\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 33/33 [00:00<00:00, 173.39it/s]\n",
      "Generating embeddings: 100%|██████████| 46/46 [00:03<00:00, 14.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting the text into vectors\n",
    "index=VectorStoreIndex.from_documents(documents,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# SimilarityPostprocessor : find the similar result who had min 0.80 similarity score \n",
    "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
    "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.40)\n",
    "\n",
    "query_engine=RetrieverQueryEngine(retriever=retriever,\n",
    "                                  node_postprocessors=[postprocessor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = query_engine.query(\"what is Chain-of-thought Prompt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Chain-of-thought Prompt is a method that enhances the\n",
      "inference of Large Language Models (LLMs) by incorporating an\n",
      "intermediate reasoning step to identify cues present in the dialogue\n",
      "context. This method aims to provide more personalized and engaging\n",
      "responses by prompting the models to reason based on the user status\n",
      "exhibited in the conversation.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: 496d2db7-4836-4a48-80d3-252b3185d2df\n",
      "Similarity: 0.821114264578233\n",
      "Text: to a test query sample while some works utilize uncertainty\n",
      "(Diao et al., 2023) or diversity (Li and Qiu, 2023) to refine and\n",
      "evaluate the selected exam- ples. Also, few works (Deng et al., 2023a)\n",
      "focus on the intermediate reasoning steps, and they use the reasoning\n",
      "complexity (Fu et al., 2023), i.e., chains with more reasoning steps,\n",
      "making the...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: 93ca4df7-20cb-42ea-bed6-2869cb183cd8\n",
      "Similarity: 0.819288011819285\n",
      "Text: Cue-CoT: Chain-of-thought Prompting for Responding to In-depth\n",
      "Dialogue Questions with LLMs Hongru Wang1∗, Rui Wang2,6∗, Fei Mi3,\n",
      "Yang Deng4, Zezhong Wang1 Bin Liang1, Ruifeng Xu2,5,6, Kam-Fai Wong1†\n",
      "1MoE Key Laboratory of High Confidence Software Technologies The\n",
      "Chinese University of Hong Kong 2Harbin Institute of Technology,\n",
      "Shenzhen, China3H...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: 49680488-d590-4c28-a0d5-0e137151bdf6\n",
      "Similarity: 0.7929419149092187\n",
      "Text: Specifi- cally, the linguistic cues underlying dialogue con-\n",
      "text have been shown to be an effective means of revealing the\n",
      "emotions (Ekman, 1971), personality traits (Mairesse et al., 2007),\n",
      "psychological char- acteristics (Tausczik and Pennebaker, 2010), and\n",
      "other relevant information of users (Turney, 2002; Newman et al.,\n",
      "2003). Consequently,...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: 4c524f79-d6e4-4c89-9a66-cfd2c5791f53\n",
      "Similarity: 0.7876291609821469\n",
      "Text: We then propose aCue-CoT to trace the status of users, decompos-\n",
      "ing the response generation into multiple reasoning steps.\n",
      "Experimental results demonstrate the su- perior performance of our\n",
      "method on 6 datasets under both zero-shot and one-shot settings. We\n",
      "hope the release of our work can shed some light on the evaluation and\n",
      "development of LL...\n",
      "Chain-of-thought Prompt is a method that enhances the inference of Large Language Models (LLMs) by incorporating an intermediate reasoning step to identify cues present in the dialogue context. This method aims to provide more personalized and engaging responses by prompting the models to reason based on the user status exhibited in the conversation.\n"
     ]
    }
   ],
   "source": [
    "# Checking other similar responses\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "pprint_response(responses,show_source=True)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are a model architecture that relies entirely on an attention mechanism to draw global dependencies between input and output sequences. They eschew recurrence and instead use self-attention to compute representations of the input and output without relying on sequence-aligned recurrent neural networks or convolutional layers.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are transformers?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
